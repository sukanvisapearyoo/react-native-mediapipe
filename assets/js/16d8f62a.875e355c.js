"use strict";(self.webpackChunkdocsite=self.webpackChunkdocsite||[]).push([[605],{4318:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>m,frontMatter:()=>s,metadata:()=>o,toc:()=>l});var t=i(4848),r=i(8453);const s={sidebar_position:8},a="Face Landmark Detection",o={id:"api_pages/face-landmark-detection",title:"Face Landmark Detection",description:"Detects the main points of the face and its expressions in real time.",source:"@site/docs/api_pages/face-landmark-detection.md",sourceDirName:"api_pages",slug:"/api_pages/face-landmark-detection",permalink:"/react-native-mediapipe/docs/api_pages/face-landmark-detection",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:8,frontMatter:{sidebar_position:8},sidebar:"tutorialSidebar",previous:{title:"Face Detection",permalink:"/react-native-mediapipe/docs/api_pages/face-detection"},next:{title:"Pose Landmark Detection",permalink:"/react-native-mediapipe/docs/api_pages/pose-landmark-detection"}},c={},l=[{value:"How to get started",id:"how-to-get-started",level:2}];function d(e){const n={a:"a",admonition:"admonition",blockquote:"blockquote",code:"code",em:"em",h1:"h1",h2:"h2",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h1,{id:"face-landmark-detection",children:"Face Landmark Detection"}),"\n",(0,t.jsx)(n.p,{children:"Detects the main points of the face and its expressions in real time."}),"\n",(0,t.jsxs)(n.p,{children:["For more details or to demo it, visit\n",(0,t.jsx)(n.a,{href:"https://mediapipe-studio.webapps.google.com/studio/demo/face_landmarker",children:"MediaPipe - Face Landmark Detection"})]}),"\n",(0,t.jsx)(n.h2,{id:"how-to-get-started",children:"How to get started"}),"\n",(0,t.jsx)(n.p,{children:"** Using yarn **"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Requirements"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Gradle minimum SDK 24 or higher"}),"\n",(0,t.jsx)(n.li,{children:"Android-SDK Version 26 or higher"}),"\n",(0,t.jsx)(n.li,{children:"iOS 12 or higher"}),"\n"]}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Open Terminal or Command Prompt:"})," Open your terminal or command prompt application. Create a brand new React Native Project. In this case we will be using ",(0,t.jsx)(n.strong,{children:"'eyetracker'"})," as on React Native MediaPipe Demo for example."]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"npx react-native init eyetracker\n"})}),"\n",(0,t.jsxs)(n.ol,{start:"2",children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Navigate to Your Project Directory:"})," Navigate to your React Native project directory on your environment."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Install React Native MediaPipe:"})," Run the following command to install React Native MediaPipe and its dependencies:"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"yarn add react-native-mediapipe react-native-vision-camera react-native-worklets-core\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"yarn add @shopify/react-native-skia react-native-reanimated\n"})}),"\n",(0,t.jsxs)(n.ol,{start:"4",children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Configuring Babel:"})," Navigate to the 'babel.config.js' file and add:"]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-jsx",children:"module.exports = {\n  presets: ['module:@react-native/babel-preset'],\n  plugins: [['react-native-worklets-core/plugin']],\n};\n"})}),"\n",(0,t.jsx)(n.p,{children:"Updating Manifests"}),"\n",(0,t.jsxs)(n.ol,{start:"5",children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Configuring Gradle:"})," Navigate to the 'android/build.gradle' file and change minSdkVersion to 24"]}),"\n"]}),"\n",(0,t.jsx)(n.admonition,{type:"warning",children:(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Gradle minimum SDK"})," must be 24 or higher to run"]})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"buildscript {\n    ext {\n        ...\n        minSdkVersion = 24 \n        ...\n    }\n    ...\n}\n\n"})}),"\n",(0,t.jsxs)(n.ol,{start:"6",children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Give Permissions:"})," Navigate to your AndroidManifest.xml file and add:"]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-xml",children:'<manifest xmlns:android="http://schemas.android.com/apk/res/android">\n    <uses-feature ... >\n    <uses-feature ... >\n\n    <uses-permission android:name ="android.permission.INTERNET"/>\n    <uses-permission android:name ="android.permission.CAMERA"/>\n    ...\n'})}),"\n",(0,t.jsx)(n.admonition,{type:"info",children:(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"You must change the main Android manifest file"})," not the debugging one"]})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"iOS:"})," Navigate to your ",(0,t.jsx)(n.strong,{children:"info.plist"})," file:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-jsx",children:"// add this at line 11 right after the <\/script> tag\n\n  <key>NSCameraUsageDescription</key>\n  <string>$(PRODUCT_NAME) needs access to your Camera.</string>\n"})}),"\n",(0,t.jsxs)(n.ol,{start:"7",children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Terminal Commands:"})," In your terminal run the following commands"]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"cd ios\nbundle install\npod install\n"})}),"\n",(0,t.jsx)(n.admonition,{type:"info",children:(0,t.jsx)(n.p,{children:"You will only need to run the bundle install command once."})}),"\n",(0,t.jsxs)(n.ol,{start:"8",children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Locate the configuration file"}),": Dowload and save the configuration file from ",(0,t.jsx)(n.a,{href:"https://ai.google.dev/edge/mediapipe/solutions/vision/face_landmarker#models",children:"this link."})," and into your project."]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Android:"})," it goes into your 'assets' folder"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"mkdir android/app/src/main/assets\n"})}),"\n",(0,t.jsx)(n.p,{children:"then"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"cp ~/Downloads/face_landmarker.task android/app/src/main/assets/\n"})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"iOS:"})," ",(0,t.jsx)(n.em,{children:"remainder"})," * eyetracker is the example project name we are currently using."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"ls ios/eyetracker\n"})}),"\n",(0,t.jsx)(n.p,{children:"then"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"cp ~/Downloads/face_landmarker.task ios/eyetracker\n"})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.em,{children:"optional"})," * to make sure the file is in your project"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"ls ios/eyetracker\n"})}),"\n",(0,t.jsxs)(n.ol,{start:"9",children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Xcode Launching"}),":"]}),"\n"]}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["Boot ",(0,t.jsx)(n.strong,{children:"Xcode"})," on your computer"]}),"\n",(0,t.jsxs)(n.li,{children:["Open existing project, in this case ",(0,t.jsx)(n.strong,{children:"eyetracker"})]}),"\n",(0,t.jsxs)(n.li,{children:["Go to to your ",(0,t.jsx)(n.strong,{children:"ios"})," folder"]}),"\n",(0,t.jsxs)(n.li,{children:["Choose the ",(0,t.jsx)(n.strong,{children:"eyetracker.xcworkspace"})]}),"\n",(0,t.jsxs)(n.li,{children:["Navigate to your ",(0,t.jsx)(n.strong,{children:"eyetracker"})," folder inside your ",(0,t.jsx)(n.strong,{children:"eyetracker"})," directory"]}),"\n",(0,t.jsxs)(n.li,{children:["Add the ",(0,t.jsx)(n.strong,{children:"face_landmarker.task"})," into your ",(0,t.jsx)(n.strong,{children:"eyetracker"})," folder"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.admonition,{type:"warning",children:(0,t.jsx)(n.p,{children:"Always use the file that ends on '.xcworkspace' on your xcode"})}),"\n",(0,t.jsx)(n.admonition,{type:"info",children:(0,t.jsx)(n.p,{children:"If you do pod install remember to close xcode, do pod install and restart the app. Because the pod install will change your file."})}),"\n",(0,t.jsxs)(n.ol,{start:"10",children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Run your app"}),":"]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"cd ..\nyarn start\nyarn android\n\nor\n\nyarn ios\n"})}),"\n",(0,t.jsxs)(n.ol,{start:"11",children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Add Object Detection to your app"}),": once you see the default React Native welcome page on your device, change your ",(0,t.jsx)(n.strong,{children:"App.tsx"})," code to the following one"]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-jsx",children:"import {Canvas, Line, vec} from '@shopify/react-native-skia';\nimport React from 'react';\nimport {SafeAreaView, StyleSheet, Text, View} from 'react-native';\nimport {\n  Delegate,\n  Dims,\n  MediapipeCamera,\n  Point,\n  RunningMode,\n  denormalizePoint,\n  faceLandmarkDetectionModuleConstants,\n  framePointToView,\n  useFaceLandmarkDetection,\n} from 'react-native-mediapipe';\nimport {useCameraPermission} from 'react-native-vision-camera';\n\n// we are going to draw a series of line segments\ntype DrawSegment = {\n  startPoint: Point;\n  endPoint: Point;\n};\n\n// this code converts each segment from the \"normalized\" coordinate space\n// that the face landmarks are in (0-1) to the \"view\" coordinate space\nexport function convertToViewSpace(\n  segment: DrawSegment,\n  frameSize: Dims,\n  viewSize: Dims,\n  mirrored = false,\n): DrawSegment {\n  return {\n    startPoint: framePointToView(\n      denormalizePoint(segment.startPoint, frameSize),\n      frameSize,\n      viewSize,\n      'cover',\n      mirrored,\n    ),\n    endPoint: framePointToView(\n      denormalizePoint(segment.endPoint, frameSize),\n      frameSize,\n      viewSize,\n      'cover',\n      mirrored,\n    ),\n  };\n}\n\nconst eyeLandmarks = {\n  left: faceLandmarkDetectionModuleConstants().knownLandmarks.leftEye,\n  right: faceLandmarkDetectionModuleConstants().knownLandmarks.rightEye,\n};\n\nfunction App(): React.JSX.Element {\n  const cameraPermission = useCameraPermission();\n  const [segments, setSegments] = React.useState<DrawSegment[]>([\n    {startPoint: {x: 10, y: 10}, endPoint: {x: 100, y: 100}},\n  ]);\n  const faceDetection = useFaceLandmarkDetection(\n    (results, viewSize, mirrored) => {\n      const landmarks = results.results[0].faceLandmarks[0];\n      if (!landmarks || landmarks.length === 0) {\n        return;\n      }\n      console.log(\n        JSON.stringify({\n          infTime: results.inferenceTime,\n          howManyLandmarks: landmarks.length,\n        }),\n      );\n      const frameSize = {\n        width: results.inputImageWidth,\n        height: results.inputImageHeight,\n      };\n\n      // get all the segments for the eyes\n      const leftEyeSegments: DrawSegment[] = eyeLandmarks.left.map(seg =>\n        convertToViewSpace(\n          {\n            startPoint: landmarks[seg.start],\n            endPoint: landmarks[seg.end],\n          },\n          frameSize,\n          viewSize,\n          mirrored,\n        ),\n      );\n      const rightEyeSegments: DrawSegment[] = eyeLandmarks.right.map(seg =>\n        convertToViewSpace(\n          {\n            startPoint: landmarks[seg.start],\n            endPoint: landmarks[seg.end],\n          },\n          frameSize,\n          viewSize,\n          mirrored,\n        ),\n      );\n      setSegments([leftEyeSegments, rightEyeSegments].flat());\n    },\n    error => {\n      console.error(`onError: ${error}`);\n    },\n    RunningMode.LIVE_STREAM,\n    'face_landmarker.task',\n    {\n      delegate: Delegate.GPU,\n    },\n  );\n\n  return (\n    <SafeAreaView style={styles.root}>\n      {cameraPermission.hasPermission ? (\n        <View style={styles.container}>\n          <MediapipeCamera style={styles.camera} solution={faceDetection} />\n          <Canvas style={styles.overlay}>\n            {segments.map((segment, index) => (\n              <Line\n                key={index}\n                p1={vec(segment.startPoint.x, segment.startPoint.y)}\n                p2={vec(segment.endPoint.x, segment.endPoint.y)}\n                color=\"red\"\n                style=\"stroke\"\n                strokeWidth={4}\n              />\n            ))}\n          </Canvas>\n        </View>\n      ) : (\n        <RequestPermissions\n          hasCameraPermission={cameraPermission.hasPermission}\n          requestCameraPermission={cameraPermission.requestPermission}\n        />\n      )}\n    </SafeAreaView>\n  );\n}\n\nconst RequestPermissions: React.FC<{\n  hasCameraPermission: boolean;\n  requestCameraPermission: () => Promise<boolean>;\n}> = ({hasCameraPermission, requestCameraPermission}) => {\n  console.log(hasCameraPermission);\n  return (\n    <View style={styles.container}>\n      <Text style={styles.welcome}>Welcome to React Native Mediapipe</Text>\n      <View style={styles.permissionsContainer}>\n        {!hasCameraPermission && (\n          <Text style={styles.permissionText}>\n            React Native Mediapipe needs{' '}\n            <Text style={styles.bold}>Camera permission</Text>.{' '}\n            <Text style={styles.hyperlink} onPress={requestCameraPermission}>\n              Grant\n            </Text>\n          </Text>\n        )}\n      </View>\n    </View>\n  );\n};\n\nconst styles = StyleSheet.create({\n  root: {\n    flex: 1,\n    justifyContent: 'center',\n    alignItems: 'center',\n    color: 'black',\n  },\n  welcome: {color: 'black', fontSize: 38, fontWeight: 'bold', maxWidth: '80%'},\n  banner: {\n    position: 'absolute',\n    opacity: 0.4,\n    bottom: 0,\n    left: 0,\n  },\n  container: {\n    height: '100%',\n    width: '100%',\n    backgroundColor: 'white',\n    flexDirection: 'column',\n    position: 'relative',\n  },\n  camera: {\n    flex: 1,\n  },\n  overlay: {\n    position: 'absolute',\n    top: 0,\n    left: 0,\n    right: 0,\n    bottom: 0,\n  },\n  categoriesText: {color: 'black', fontSize: 36},\n  permissionsContainer: {\n    marginTop: 30,\n  },\n  permissionText: {\n    color: 'black',\n    fontSize: 17,\n  },\n  hyperlink: {\n    color: '#007aff',\n    fontWeight: 'bold',\n  },\n  bold: {\n    fontWeight: 'bold',\n  },\n});\n\nexport default App;\n\n"})}),"\n",(0,t.jsxs)(n.ol,{start:"12",children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Reload app"}),": and grant acces to camera permissions"]}),"\n"]})]})}function m(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>a,x:()=>o});var t=i(6540);const r={},s=t.createContext(r);function a(e){const n=t.useContext(s);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),t.createElement(s.Provider,{value:n},e.children)}}}]);